{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the activation function and its derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    return x * (1.0 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define feature and target data. There are three feature variables, one target variable, and four data items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_x_y():\n",
    "    x = np.array([\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [1, 1]\n",
    "    ])\n",
    "\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the number of hidden layers, nodes in each hidden layer, and nodes in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_hyperparameters(x):\n",
    "    n_training_samples = x.shape[0]\n",
    "    n_nodes_input = x.shape[1]\n",
    "    n_nodes_hidden = 2\n",
    "    n_nodes_output = 1\n",
    "    n_hidden_layers = 2\n",
    "    learning_rate = np.array([5])\n",
    "    n_epochs = 10000\n",
    "    \n",
    "    return n_training_samples, n_nodes_input, n_nodes_hidden, n_nodes_output, n_hidden_layers, learning_rate, n_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initalise_parameters(n_training_samples, n_nodes_input, n_nodes_hidden, n_nodes_output, n_hidden_layers, learning_rate, n_epochs):\n",
    "    w_input = np.random.rand(n_nodes_input, n_nodes_hidden)\n",
    "    b_input = np.random.rand(n_nodes_hidden)\n",
    "\n",
    "    w_hidden = np.random.rand(n_nodes_hidden, n_nodes_hidden, n_hidden_layers - 1)\n",
    "    b_hidden = np.random.rand(n_nodes_hidden, n_hidden_layers - 1)\n",
    "\n",
    "    w_output = np.random.rand(n_nodes_hidden, n_nodes_output)\n",
    "    b_output = np.random.rand(n_nodes_output)\n",
    "    \n",
    "    return w_input, b_input, w_hidden, b_hidden, w_output, b_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise a cache to store the activations of each node in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_a_z_cache(n_training_samples, n_nodes_hidden, n_hidden_layers):\n",
    "    z_hidden = np.zeros(shape = [n_training_samples, n_nodes_hidden, n_hidden_layers])\n",
    "    a_hidden = np.zeros(shape = [n_training_samples, n_nodes_hidden, n_hidden_layers])\n",
    "    \n",
    "    return z_hidden, a_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for the forward propogation through the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propogate_forward(x, n_hidden_layers,\n",
    "            w_input, b_input,\n",
    "            w_hidden, b_hidden, \n",
    "            w_output, b_output,\n",
    "            z_hidden, a_hidden):\n",
    "    \n",
    "    z = np.dot(x, w_input) + b_input\n",
    "    a = sigmoid(z)\n",
    "    \n",
    "    z_hidden[:, :, 0] = z\n",
    "    a_hidden[:, :, 0] = a\n",
    "    \n",
    "    for i in range(0, n_hidden_layers - 1):\n",
    "        z = np.dot(a, w_hidden[:, :, i]) + b_hidden[:, i]\n",
    "        a = sigmoid(z)\n",
    "        z_hidden[:, :, i + 1] = z\n",
    "        a_hidden[:, :, i + 1] = a\n",
    "        \n",
    "    z_output = np.dot(z, w_output) + b_output\n",
    "    a_output = sigmoid(z_output)\n",
    "    \n",
    "    return z_hidden, a_hidden, z_output, a_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(a_output, y, n_training_samples):\n",
    "    return 0.5 * np.sum((a_output.T - y) ** 2) / n_training_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propogate_backward(a_hidden, z_hidden,\n",
    "                       a_output, z_output,\n",
    "                       w_input, b_input,\n",
    "                       w_hidden, b_hidden, \n",
    "                       w_output, b_output,\n",
    "                       n_hidden_layers,\n",
    "                       learning_rate, y):\n",
    "    \n",
    "    d_z = (a_output.T - y) * d_sigmoid(a_output).T / n_training_samples\n",
    "    d_w = np.dot(d_z, a_hidden[:, :, n_hidden_layers - 1])\n",
    "    d_b = np.sum(d_z, axis = 1)\n",
    "    \n",
    "    w_output -= (learning_rate * d_w).T\n",
    "    b_output -= learning_rate * d_b\n",
    "    \n",
    "    w_next = w_output\n",
    "    \n",
    "    for i in range(n_hidden_layers - 1, 0, -1):\n",
    "        d_z = np.dot(w_next, d_z) * d_sigmoid(a_hidden[:, :, i]).T / n_training_samples\n",
    "        d_w = np.dot(d_z, a_hidden[:, :, i - 1])\n",
    "        d_b = np.sum(d_z, axis = 1)\n",
    "        \n",
    "        w_hidden[:, :, i - 1] -= learning_rate * d_w\n",
    "        b_hidden[:, i - 1] -= learning_rate * d_b\n",
    "        \n",
    "        w_next = w_hidden[:, :, i - 1]\n",
    "        \n",
    "    d_z = np.dot(w_next, d_z) * d_sigmoid(a_hidden[:, :, 0]).T / n_training_samples\n",
    "    d_w = np.dot(d_z, x)\n",
    "    d_b = np.sum(d_z, axis = 1)\n",
    "    \n",
    "    w_input -= (learning_rate * d_w).T\n",
    "    b_input -= learning_rate * d_b\n",
    "        \n",
    "    return w_input, b_input, w_hidden, b_hidden, w_output, b_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_hidden_layers - 1, 0, -1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, \n",
    "          n_epochs, n_training_samples, n_hidden_layers,\n",
    "          w_input, b_input,\n",
    "          w_hidden, b_hidden,\n",
    "          w_output, b_output,\n",
    "          z_hidden, a_hidden):\n",
    "\n",
    "    for i in range(0, n_epochs):\n",
    "        z_hidden, a_hidden, z_output, a_output = propogate_forward(x, n_hidden_layers,\n",
    "                                                                   w_input, b_input,\n",
    "                                                                   w_hidden, b_hidden, \n",
    "                                                                   w_output, b_output,\n",
    "                                                                   z_hidden, a_hidden)\n",
    "\n",
    "        w_input, b_input, w_hidden, b_hidden, w_output, b_output = propogate_backward(a_hidden, z_hidden,\n",
    "                                                                                      a_output, z_output,\n",
    "                                                                                      w_input, b_input,\n",
    "                                                                                      w_hidden, b_hidden, \n",
    "                                                                                      w_output, b_output,\n",
    "                                                                                      n_hidden_layers,\n",
    "                                                                                      learning_rate, y)\n",
    "    \n",
    "    z_hidden, a_hidden, z_output, a_output = propogate_forward(x, n_hidden_layers,\n",
    "                                                               w_input, b_input,\n",
    "                                                               w_hidden, b_hidden, \n",
    "                                                               w_output, b_output,\n",
    "                                                               z_hidden, a_hidden)\n",
    "    \n",
    "    loss = calc_loss(a_output, y, n_training_samples)\n",
    "    \n",
    "    return a_output, y, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_a_z_cache(n_training_samples, n_nodes_hidden, n_hidden_layers):\n",
    "    z_hidden = np.zeros(shape = [n_training_samples, n_nodes_hidden, n_hidden_layers])\n",
    "    a_hidden = np.zeros(shape = [n_training_samples, n_nodes_hidden, n_hidden_layers])\n",
    "    \n",
    "    return z_hidden, a_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03842953 0.96968537 0.97106383 0.03861592]]\n",
      "[0 1 1 0]\n",
      "0.0005905371826493944\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "x, y = initialise_x_y()\n",
    "\n",
    "n_training_samples, n_nodes_input, n_nodes_hidden, \\\n",
    "n_nodes_output, n_hidden_layers, learning_rate, n_epochs = initialise_hyperparameters(x)\n",
    "\n",
    "w_input, b_input, w_hidden, b_hidden, w_output, b_output = \\\n",
    "initalise_parameters(n_training_samples, n_nodes_input, n_nodes_hidden, n_nodes_output, \n",
    "                     n_hidden_layers, learning_rate, n_epochs)\n",
    "\n",
    "z_hidden, a_hidden = initialise_a_z_cache(n_training_samples, n_nodes_hidden, n_hidden_layers)\n",
    "\n",
    "a_output, y, loss = train(x, y, \n",
    "                          n_epochs, n_training_samples, n_hidden_layers,\n",
    "                          w_input, b_input,\n",
    "                          w_hidden, b_hidden,\n",
    "                          w_output, b_output,\n",
    "                          z_hidden, a_hidden)\n",
    "\n",
    "print(a_output.T)\n",
    "print(y)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
